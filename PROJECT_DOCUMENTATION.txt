======================================================================
项目整体工作与文件说明
======================================================================

1. 本次工作概述
-----------------
- 全面审阅当前仓库中的数据收集、清洗、情绪分析与三种模型训练脚本，确认它们在最新一次重构后的依赖关系和运行顺序。
- 梳理每个 Python 脚本、数据文件以及补充资料的用途，并核实它们在仓库中的存放路径。
- 编写本说明文档，集中记录工作内容、文件作用说明、完整的项目运行指南，以及关键输出文件的存储位置，方便团队成员快速理解并执行整个流程。

2. 仓库中文件用途与位置一览
------------------------------
以下按功能模块列出仓库内的主要文件及其路径（相对路径均以仓库根目录 `kevin/` 为基准）：

数据收集脚本
^^^^^^^^^^^^
- `collect_stock_data.py`：通过 `yfinance` 下载指定股票（默认 QQQ）在给定时间范围内的历史行情，并写入 `stock_price.csv`。
- `collect_news_rss.py`：使用多个实时财经 RSS 源抓取近期新闻，生成基础的 `news.csv`。适合快速获取最近新闻。
- `collect_news_finance_rss.py`：面向 2020-2024 年的稳定财经 RSS 抓取脚本，可批量获取可靠的财经新闻并生成 `news.csv`。
- `collect_news_yahoo.py`：调用 `yfinance` 内置新闻接口，为指定股票抓取最近的 Yahoo Finance 新闻，输出 `news.csv`。
- `collect_news_gdelt.py`：通过 GDELT API 按月批量抓取历史新闻，字段自适应处理，覆盖 2015-2023 年，输出 `news.csv`。

数据处理与分析
^^^^^^^^^^^^^^
- `clean_news_data.py`：对 `news.csv` 去重、统一日期格式，并与股价交易日对齐，生成 `news_data.csv`。
- `analyze_sentiment.py`：加载清洗后的新闻，对标题执行 FinBERT 情绪分析，按日聚合后与股价对齐，输出 `sentiment.csv` 及调试文件 `sentiment_daily_debug.csv`。
- `clean_news_data.py`、`analyze_sentiment.py` 都依赖 `stock_price.csv` 以及前序新闻采集脚本的输出。

模型训练与评估
^^^^^^^^^^^^^^^^
- `train_model_mlp.py`：基于股价单变量序列训练多层感知机，报告 MAE/MAPE/Accuracy。
- `train_model_lstm.py`：构建单变量 LSTM 模型，流程包括滑动窗口、缩放、训练与指标输出。
- `train_model_finbert_lstm.py`：将股价与 `sentiment.csv` 中的 FinBERT 情绪得分拼接成多变量序列，训练融合特征的 LSTM。
- `compare_models.py`：示例性地对比三类模型的预测结果并绘图，使用脚本内部硬编码的预测数组。
- `quick_test.py`：快速自检脚本，以 5 个 epoch 训练 MLP，验证数据管道是否可运行。

流程调度与辅助文档
^^^^^^^^^^^^^^^^^^
- `run_full_pipeline.py`：管道入口脚本，依次调用数据收集、清洗、情绪分析与三种模型训练脚本，便于一键式执行。
- `requirements.txt`：项目所需的 Python 依赖列表。
- `PROJECT_SUMMARY.md`、`DATA_COLLECTION_ATTEMPTS.md`、`DATA_VERIFICATION_REPORT.md`、`README_OLD.md`、`项目使用指引.txt`：历史记录与补充说明，包含早期尝试、验证结果及中文使用指引。

数据文件
^^^^^^^^^
- `stock_price.csv`：股价下载脚本的输出，供后续模型与清洗脚本使用。
- `news.csv`：任一新闻采集脚本输出的原始新闻数据。
- `news_data.csv`：`clean_news_data.py` 输出的交易日对齐新闻。
- `sentiment.csv`：`analyze_sentiment.py` 输出的 FinBERT 日均情绪得分。
- `sentiment_daily_debug.csv`：情绪分析脚本生成的调试文件，包含日期、平均情绪及新闻数量。
- `backup_data/` 目录：存放 `news_data.csv`、`news.csv`、`sentiment.csv`、`stock_price.csv` 的备份。

3. 正确运行项目的推荐流程
---------------------------
1. 环境准备：
   - 使用 Python 3.9+ 环境（建议创建虚拟环境）。
   - 安装依赖：`pip install -r requirements.txt`。
   - 如需使用 GPU，请正确配置 CUDA/cuDNN，FinBERT 会自动检测 GPU。
2. 数据收集：
   - 运行 `python collect_stock_data.py` 获取股价数据。
   - 根据需要选择一种新闻采集脚本运行，例如 `python collect_news_rss.py`（近实时）、`python collect_news_finance_rss.py`（稳定财经 RSS）、`python collect_news_yahoo.py` 或 `python collect_news_gdelt.py`（历史数据）。多次运行会覆盖 `news.csv`。
3. 数据清洗：
   - 执行 `python clean_news_data.py`，生成 `news_data.csv` 并保证日期与股价对齐。
4. 情绪分析：
   - 运行 `python analyze_sentiment.py`，得到 `sentiment.csv`。
5. 模型训练：
   - 可单独运行 `python train_model_mlp.py`、`python train_model_lstm.py`、`python train_model_finbert_lstm.py` 分别训练各模型。
   - 若要快速验证流水线是否通畅，可先运行 `python quick_test.py`（仅 5 个 epoch）。
6. 全流程执行（可选）：
   - 运行 `python run_full_pipeline.py` 按顺序自动执行上述各步骤。请确保每个脚本位于仓库根目录并具有运行权限。
7. 结果查看：
   - 模型训练脚本会在控制台输出 MAE/MAPE/Accuracy。
   - 训练完成后，可使用 `compare_models.py` 可视化对比预测表现（需要手动确保脚本中的数据列表更新或改为读取最新预测）。

-4. 主要文件存储位置说明
--------------------------
- 项目根目录：`/workspace/kevin/`
- 说明文档（本文件）：`/workspace/kevin/PROJECT_DOCUMENTATION.txt`
- 备份数据：`/workspace/kevin/backup_data/`
- 运行生成的主数据：
  - `stock_price.csv`、`news.csv`、`news_data.csv`、`sentiment.csv` 位于 `/workspace/kevin/`
  - 情绪分析调试文件 `sentiment_daily_debug.csv` 同样位于 `/workspace/kevin/`
- 训练脚本、数据收集脚本及辅助脚本均放置在 `/workspace/kevin/`

附录 A. 如何在本地查看这些文件
----------------------------------
1. 终端/命令行方式：
   - 切换到仓库目录：`cd /workspace/kevin`
   - 查看目录内容：`ls`（Linux/macOS）或 `dir`（Windows PowerShell/CMD）。
   - 若需打开某个文件，可使用 `cat 文件名`、`less 文件名` 或在 VS Code/IDE 中直接打开。
2. 图形界面方式：
   - 若使用远程开发容器，可在 VS Code 左侧的 Explorer 中展开 `kevin` 目录查看全部文件。
   - 如在本地电脑，将仓库克隆到任意文件夹后，可通过资源管理器/访达打开该文件夹查看。

附录 B. 如何在 GitHub 上查看这些文件
---------------------------------------
1. 首次连接 GitHub：确保本地仓库已配置远程，执行 `git remote -v` 检查；若为空，请运行 `git remote add origin <你的GitHub仓库地址>`。
2. 推送最新修改：
   - 提交变更：`git add . && git commit -m "update docs"`
   - 同步远程（可选）：`git pull origin <分支名> --rebase`
   - 推送：`git push origin <分支名>`
3. 在线查看：
   - 登录 GitHub，打开对应仓库与分支，即可在文件列表中看到 `/PROJECT_DOCUMENTATION.txt`、脚本与数据文件。
   - 点击文件名可查看内容，或使用 `Download ZIP` 将整个仓库下载到本地。

5. 后续建议
------------
- 在正式训练前，确认 `news.csv` 与 `stock_price.csv` 行数覆盖同一日期范围，以避免清洗阶段丢失大量记录。
- FinBERT 推理较耗时，若数据量大，可考虑分批保存中间结果或复用缓存。
- 如需长周期自动化，可将 `run_full_pipeline.py` 接入调度系统（如 cron、Airflow），并增加日志与错误告警。

======================================================================
6. GitHub 同步说明
------------------
- 当前代码库位于本地（或远程开发容器）路径 `/workspace/kevin/`。若要在 GitHub 上看到这些文件，需要将本地提交推送到目标仓库的远程分支。
- 推送前请确认已配置好远程仓库地址，可通过 `git remote -v` 查看；若未配置，可执行 `git remote add origin <你的GitHub仓库地址>`。
- 使用以下步骤同步：
  1. 确保所有修改已提交：`git add . && git commit -m "描述本次修改"`。
  2. 拉取远程分支，避免冲突：`git pull origin <分支名> --rebase`（初次推送可跳过）。
  3. 推送到 GitHub：`git push origin <分支名>`。
- 如果仓库设置了访问令牌，请在推送时按照提示输入 GitHub Personal Access Token。
- 推送成功后，即可在 GitHub 对应仓库与分支上看到 `PROJECT_DOCUMENTATION.txt` 及其他脚本。

附录 C. 如何将整个项目克隆到本地电脑
----------------------------------------
1. **准备工作**
   - 确保电脑已安装 [Git](https://git-scm.com/downloads)。安装完成后，在命令行执行 `git --version` 验证是否可用。
   - 选定一个用于存放项目的文件夹，例如 Windows 下的 `D:\projet\` 或 macOS/Linux 下的 `~/Projects/projet/`。
2. **从 GitHub 克隆（推荐）**
   - 获取目标仓库的 HTTPS 或 SSH 地址，例如 `https://github.com/<你的用户名>/<仓库名>.git`。
   - 在命令行切换到目标父目录：`cd D:\projet`（Windows PowerShell）或 `cd ~/Projects/`（macOS/Linux）。
   - 运行 `git clone <仓库地址>`，Git 会自动创建子文件夹并将仓库完整下载。
   - 进入仓库目录：`cd <仓库名>`，即可看到 `PROJECT_DOCUMENTATION.txt`、`FILE_LOCATIONS_OVERVIEW.txt` 等文件。
3. **如果当前仓库仅存在于本地/容器中**
   - 首先按照“附录 B”配置远程仓库并执行 `git push` 将最新内容上传到 GitHub。
   - 推送完成后，按照上面的克隆步骤在任意电脑上拉取即可。
4. **无法使用 Git 时的替代方式**
   - 在 GitHub 仓库页面点击 “<> Code” 按钮，选择 “Download ZIP” 将整个仓库打包下载。
   - 下载后解压到指定目录，即可通过资源管理器/访达查看所有文件。
   - 若需要继续开发，建议在该目录初始化 Git：`git init`，再添加远程并推送，便于与主仓库同步。
